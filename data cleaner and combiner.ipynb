{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeGNPVGRMTwR",
        "outputId": "9fb3bad6-5554-4ab2-b308-8180b82293b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… 4 CSV files combined successfully into combined_dataset.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_files = [\n",
        "    \"/content/api_data_aadhar_enrolment_0_500000.csv\",\n",
        "    \"/content/api_data_aadhar_enrolment_500000_1000000.csv\",\n",
        "    \"/content/api_data_aadhar_enrolment_1000000_1006029.csv\"\n",
        "]\n",
        "combined_df = pd.concat(\n",
        "    [pd.read_csv(file) for file in csv_files],\n",
        "    ignore_index=True\n",
        ")\n",
        "combined_df = combined_df[\n",
        "    [\n",
        "        \"date\",\n",
        "        \"state\",\n",
        "        \"district\",\n",
        "        \"pincode\",\n",
        "        \"age_0_5\",\n",
        "        \"age_5_17\",\n",
        "        \"age_18_greater\"\n",
        "    ]\n",
        "]\n",
        "combined_df.to_csv(\"enrollment.csv\", index=False)\n",
        "print(\"âœ… 4 CSV files combined successfully into combined_dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41DWm8vL6Csw",
        "outputId": "b2fcb98f-d095-467d-e010-b1b1cc50d7bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merged Dataset Head:\n",
            "        date                        state  district pincode  bio_age_5_17  \\\n",
            "0 2025-03-01  andaman and nicobar islands  andamans  744101          16.0   \n",
            "1 2025-03-01  andaman and nicobar islands   nicobar  744301         101.0   \n",
            "2 2025-03-01  andaman and nicobar islands   nicobar  744301         101.0   \n",
            "3 2025-03-01  andaman and nicobar islands   nicobar  744302          15.0   \n",
            "4 2025-03-01  andaman and nicobar islands   nicobar  744303          46.0   \n",
            "\n",
            "   bio_age_17_  demo_age_5_17  demo_age_17_  age_0_5  age_5_17  age_18_greater  \n",
            "0        193.0            0.0           0.0      0.0       0.0             0.0  \n",
            "1         48.0           16.0         180.0      0.0       0.0             0.0  \n",
            "2         48.0           16.0         180.0      0.0       0.0             0.0  \n",
            "3         12.0            0.0           0.0      0.0       0.0             0.0  \n",
            "4         27.0            0.0           0.0      0.0       0.0             0.0  \n",
            "Total rows in combined dataset: 2925076\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_bio = pd.read_csv('/content/unified_bio_data_final.csv')\n",
        "df_demo = pd.read_csv('/content/unified_demo_data_final.csv')\n",
        "df_age = pd.read_csv('/content/unified_enrol_data_final.csv')\n",
        "for df in [df_bio, df_demo, df_age]:\n",
        "    df['date'] = pd.to_datetime(df['date'], dayfirst=True, format='mixed')\n",
        "    df['pincode'] = df['pincode'].astype(str)\n",
        "    df['state'] = df['state'].str.lower().str.strip()\n",
        "    df['district'] = df['district'].str.lower().str.strip()\n",
        "merge_keys = ['date', 'state', 'district', 'pincode']\n",
        "merged_df = pd.merge(df_bio, df_demo, on=merge_keys, how='outer')\n",
        "final_df = pd.merge(merged_df, df_age, on=merge_keys, how='outer')\n",
        "metric_columns = [\n",
        "    'bio_age_5_17', 'bio_age_17_',\n",
        "    'demo_age_5_17', 'demo_age_17_',\n",
        "    'age_0_5', 'age_5_17', 'age_18_greater'\n",
        "]\n",
        "final_df[metric_columns] = final_df[metric_columns].fillna(0)\n",
        "final_df = final_df.sort_values(by=['date', 'state', 'district'])\n",
        "print(\"Merged Dataset Head:\")\n",
        "print(final_df.head())\n",
        "final_df.to_csv('unified_enrolment_data.csv', index=False)\n",
        "print(f\"Total rows in combined dataset: {len(final_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asBPY_yIgQGc",
        "outputId": "cb6b40e0-4784-49c7-fa50-5dbfaf8f7592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rapidfuzz\n",
            "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.3/3.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/3.2 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz\n",
            "Successfully installed rapidfuzz-3.14.3\n"
          ]
        }
      ],
      "source": [
        "!pip install rapidfuzz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QXsvFPIgJHF",
        "outputId": "1b996b87-7c5f-4910-a8c9-bca30c23ae8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Cleaning complete\n",
            "Rows before: 1861108\n",
            "Rows after : 1844512\n",
            "Unique states: 36\n",
            "ðŸ“ Saved to: /content/unified_bio_data_final.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from rapidfuzz import process, fuzz\n",
        "\n",
        "df = pd.read_csv(\"/content/biometric.csv\")\n",
        "\n",
        "def normalize(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = text.replace(\"&\", \"and\")\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "df[\"state_norm\"] = df[\"state\"].apply(normalize)\n",
        "\n",
        "OFFICIAL_STATES = [\n",
        "    \"Andaman and Nicobar Islands\",\n",
        "    \"Andhra Pradesh\",\n",
        "    \"Arunachal Pradesh\",\n",
        "    \"Assam\",\n",
        "    \"Bihar\",\n",
        "    \"Chandigarh\",\n",
        "    \"Chhattisgarh\",\n",
        "    \"Dadra and Nagar Haveli and Daman and Diu\",\n",
        "    \"Delhi\",\n",
        "    \"Goa\",\n",
        "    \"Gujarat\",\n",
        "    \"Haryana\",\n",
        "    \"Himachal Pradesh\",\n",
        "    \"Jammu and Kashmir\",\n",
        "    \"Jharkhand\",\n",
        "    \"Karnataka\",\n",
        "    \"Kerala\",\n",
        "    \"Ladakh\",\n",
        "    \"Lakshadweep\",\n",
        "    \"Madhya Pradesh\",\n",
        "    \"Maharashtra\",\n",
        "    \"Manipur\",\n",
        "    \"Meghalaya\",\n",
        "    \"Mizoram\",\n",
        "    \"Nagaland\",\n",
        "    \"Odisha\",\n",
        "    \"Puducherry\",\n",
        "    \"Punjab\",\n",
        "    \"Rajasthan\",\n",
        "    \"Sikkim\",\n",
        "    \"Tamil Nadu\",\n",
        "    \"Telangana\",\n",
        "    \"Tripura\",\n",
        "    \"Uttar Pradesh\",\n",
        "    \"Uttarakhand\",\n",
        "    \"West Bengal\"\n",
        "]\n",
        "\n",
        "OFFICIAL_NORM = {normalize(s): s for s in OFFICIAL_STATES}\n",
        "\n",
        "def predict_state(value, threshold=80):\n",
        "    if not value:\n",
        "        return None\n",
        "\n",
        "    match, score, _ = process.extractOne(\n",
        "        value,\n",
        "        OFFICIAL_NORM.keys(),\n",
        "        scorer=fuzz.token_sort_ratio\n",
        "    )\n",
        "\n",
        "    if score >= threshold:\n",
        "        return OFFICIAL_NORM[match]\n",
        "    return None\n",
        "\n",
        "df[\"state_predicted\"] = df[\"state_norm\"].apply(predict_state)\n",
        "\n",
        "df_clean = df[df[\"state_predicted\"].notna()].copy()\n",
        "\n",
        "df_clean[\"state\"] = df_clean[\"state_predicted\"]\n",
        "\n",
        "df_clean.drop(columns=[\"state_norm\", \"state_predicted\"], inplace=True)\n",
        "\n",
        "output_path = \"/content/unified_bio_data_final.csv\"\n",
        "df_clean.to_csv(output_path, index=False)\n",
        "\n",
        "print(\"âœ… Cleaning complete\")\n",
        "print(\"Rows before:\", len(df))\n",
        "print(\"Rows after :\", len(df_clean))\n",
        "print(\"Unique states:\", df_clean[\"state\"].nunique())\n",
        "print(f\"ðŸ“ Saved to: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPy79myftckJ",
        "outputId": "2d2a9697-8cdc-41a9-8e81-745e935d5cbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Cleaning complete\n",
            "Rows before: 2071700\n",
            "Rows after : 2054530\n",
            "Unique states: 36\n",
            "ðŸ“ Saved to: /content/unified_demo_data_final.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from rapidfuzz import process, fuzz\n",
        "\n",
        "df = pd.read_csv(\"/content/demograph.csv\")\n",
        "\n",
        "def normalize(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = text.replace(\"&\", \"and\")\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "df[\"state_norm\"] = df[\"state\"].apply(normalize)\n",
        "\n",
        "OFFICIAL_STATES = [\n",
        "    \"Andaman and Nicobar Islands\",\n",
        "    \"Andhra Pradesh\",\n",
        "    \"Arunachal Pradesh\",\n",
        "    \"Assam\",\n",
        "    \"Bihar\",\n",
        "    \"Chandigarh\",\n",
        "    \"Chhattisgarh\",\n",
        "    \"Dadra and Nagar Haveli and Daman and Diu\",\n",
        "    \"Delhi\",\n",
        "    \"Goa\",\n",
        "    \"Gujarat\",\n",
        "    \"Haryana\",\n",
        "    \"Himachal Pradesh\",\n",
        "    \"Jammu and Kashmir\",\n",
        "    \"Jharkhand\",\n",
        "    \"Karnataka\",\n",
        "    \"Kerala\",\n",
        "    \"Ladakh\",\n",
        "    \"Lakshadweep\",\n",
        "    \"Madhya Pradesh\",\n",
        "    \"Maharashtra\",\n",
        "    \"Manipur\",\n",
        "    \"Meghalaya\",\n",
        "    \"Mizoram\",\n",
        "    \"Nagaland\",\n",
        "    \"Odisha\",\n",
        "    \"Puducherry\",\n",
        "    \"Punjab\",\n",
        "    \"Rajasthan\",\n",
        "    \"Sikkim\",\n",
        "    \"Tamil Nadu\",\n",
        "    \"Telangana\",\n",
        "    \"Tripura\",\n",
        "    \"Uttar Pradesh\",\n",
        "    \"Uttarakhand\",\n",
        "    \"West Bengal\"\n",
        "]\n",
        "\n",
        "OFFICIAL_NORM = {normalize(s): s for s in OFFICIAL_STATES}\n",
        "\n",
        "def predict_state(value, threshold=80):\n",
        "    if not value:\n",
        "        return None\n",
        "\n",
        "    match, score, _ = process.extractOne(\n",
        "        value,\n",
        "        OFFICIAL_NORM.keys(),\n",
        "        scorer=fuzz.token_sort_ratio\n",
        "    )\n",
        "\n",
        "    if score >= threshold:\n",
        "        return OFFICIAL_NORM[match]\n",
        "    return None\n",
        "\n",
        "df[\"state_predicted\"] = df[\"state_norm\"].apply(predict_state)\n",
        "\n",
        "df_clean = df[df[\"state_predicted\"].notna()].copy()\n",
        "\n",
        "df_clean[\"state\"] = df_clean[\"state_predicted\"]\n",
        "\n",
        "df_clean.drop(columns=[\"state_norm\", \"state_predicted\"], inplace=True)\n",
        "\n",
        "output_path = \"/content/unified_demo_data_final.csv\"\n",
        "df_clean.to_csv(output_path, index=False)\n",
        "\n",
        "print(\"âœ… Cleaning complete\")\n",
        "print(\"Rows before:\", len(df))\n",
        "print(\"Rows after :\", len(df_clean))\n",
        "print(\"Unique states:\", df_clean[\"state\"].nunique())\n",
        "print(f\"ðŸ“ Saved to: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhpYD7J7tdZK",
        "outputId": "b8e6b25d-dfef-47a6-95b0-1123ce5c1c2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Cleaning complete\n",
            "Rows before: 1006029\n",
            "Rows after : 1001566\n",
            "Unique states: 36\n",
            "ðŸ“ Saved to: /content/unified_enrol_data_final.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from rapidfuzz import process, fuzz\n",
        "\n",
        "df = pd.read_csv(\"/content/enrollment.csv\")\n",
        "\n",
        "def normalize(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = text.replace(\"&\", \"and\")\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "df[\"state_norm\"] = df[\"state\"].apply(normalize)\n",
        "\n",
        "OFFICIAL_STATES = [\n",
        "    \"Andaman and Nicobar Islands\",\n",
        "    \"Andhra Pradesh\",\n",
        "    \"Arunachal Pradesh\",\n",
        "    \"Assam\",\n",
        "    \"Bihar\",\n",
        "    \"Chandigarh\",\n",
        "    \"Chhattisgarh\",\n",
        "    \"Dadra and Nagar Haveli and Daman and Diu\",\n",
        "    \"Delhi\",\n",
        "    \"Goa\",\n",
        "    \"Gujarat\",\n",
        "    \"Haryana\",\n",
        "    \"Himachal Pradesh\",\n",
        "    \"Jammu and Kashmir\",\n",
        "    \"Jharkhand\",\n",
        "    \"Karnataka\",\n",
        "    \"Kerala\",\n",
        "    \"Ladakh\",\n",
        "    \"Lakshadweep\",\n",
        "    \"Madhya Pradesh\",\n",
        "    \"Maharashtra\",\n",
        "    \"Manipur\",\n",
        "    \"Meghalaya\",\n",
        "    \"Mizoram\",\n",
        "    \"Nagaland\",\n",
        "    \"Odisha\",\n",
        "    \"Puducherry\",\n",
        "    \"Punjab\",\n",
        "    \"Rajasthan\",\n",
        "    \"Sikkim\",\n",
        "    \"Tamil Nadu\",\n",
        "    \"Telangana\",\n",
        "    \"Tripura\",\n",
        "    \"Uttar Pradesh\",\n",
        "    \"Uttarakhand\",\n",
        "    \"West Bengal\"\n",
        "]\n",
        "\n",
        "OFFICIAL_NORM = {normalize(s): s for s in OFFICIAL_STATES}\n",
        "\n",
        "def predict_state(value, threshold=80):\n",
        "    if not value:\n",
        "        return None\n",
        "\n",
        "    match, score, _ = process.extractOne(\n",
        "        value,\n",
        "        OFFICIAL_NORM.keys(),\n",
        "        scorer=fuzz.token_sort_ratio\n",
        "    )\n",
        "\n",
        "    if score >= threshold:\n",
        "        return OFFICIAL_NORM[match]\n",
        "    return None\n",
        "\n",
        "df[\"state_predicted\"] = df[\"state_norm\"].apply(predict_state)\n",
        "\n",
        "df_clean = df[df[\"state_predicted\"].notna()].copy()\n",
        "\n",
        "df_clean[\"state\"] = df_clean[\"state_predicted\"]\n",
        "\n",
        "df_clean.drop(columns=[\"state_norm\", \"state_predicted\"], inplace=True)\n",
        "\n",
        "output_path = \"/content/unified_enrol_data_final.csv\"\n",
        "df_clean.to_csv(output_path, index=False)\n",
        "\n",
        "print(\" Cleaning complete\")\n",
        "print(\"Rows before:\", len(df))\n",
        "print(\"Rows after :\", len(df_clean))\n",
        "print(\"Unique states:\", df_clean[\"state\"].nunique())\n",
        "print(f\" Saved to: {output_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
